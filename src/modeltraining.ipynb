{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "#from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error,mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from catboost import CatBoostRegressor\n",
    "#from xgboost import XGBRegressor \n",
    "import warnings\n",
    "import logger\n",
    "from dataclasses import dataclass\n",
    "from utils import save_object,evaluate_models\n",
    "from exception import CustomException\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data_and_eda/data/alzheimers_disease_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('PatientID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('DoctorInCharge',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Diagnosis',axis=1)\n",
    "y=df['Diagnosis']\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=DecisionTreeClassifier()\n",
    "model1.fit(xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=model1.predict(xtest)\n",
    "r2_square=r2_score(ytest,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6049808199472548"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7017202109805802\n"
     ]
    }
   ],
   "source": [
    "model2=AdaBoostClassifier()\n",
    "model2.fit(xtrain,ytrain)\n",
    "predicted1=model2.predict(xtest)\n",
    "r2_square1=r2_score(ytest,predicted1)\n",
    "print(r2_square1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9684014869888475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "model3=RandomForestClassifier(bootstrap= False, max_depth= 20, max_features='log2', min_samples_leaf= 1, min_samples_split= 10, n_estimators= 200)\n",
    "model3.fit(xtrain,ytrain)\n",
    "predicted2=model3.predict(xtest)\n",
    "accuracy_score1=accuracy_score(ytest,predicted2)\n",
    "print(accuracy_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best parameters found:  {'bootstrap': False, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best accuracy:  0.9379189662134877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(xtrain, ytrain)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kodit\\onedrive\\desktop\\alzheimer-disease-detection\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU,ReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Dense(units=6,activation='relu'))\n",
    "classifier.add(Dense(units=12,activation='relu'))\n",
    "classifier.add(Dense(units=6,activation='relu'))\n",
    "classifier.add(Dense(units=12,activation='relu'))\n",
    "classifier.add(Dense(units=6,activation='relu'))\n",
    "classifier.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) #adam uses a learning rate of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/360\n",
      "108/108 [==============================] - 1s 3ms/step - loss: 1.2192 - accuracy: 0.5459 - val_loss: 0.6680 - val_accuracy: 0.5977\n",
      "Epoch 2/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6061 - val_loss: 0.6591 - val_accuracy: 0.6203\n",
      "Epoch 3/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6200 - val_loss: 0.6666 - val_accuracy: 0.5846\n",
      "Epoch 4/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6219 - val_loss: 0.6786 - val_accuracy: 0.5752\n",
      "Epoch 5/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6154 - val_loss: 0.6524 - val_accuracy: 0.6541\n",
      "Epoch 6/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6367 - val_loss: 0.6619 - val_accuracy: 0.6353\n",
      "Epoch 7/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6358 - val_loss: 0.6620 - val_accuracy: 0.6316\n",
      "Epoch 8/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6386 - val_loss: 0.6522 - val_accuracy: 0.6579\n",
      "Epoch 9/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6450 - val_loss: 0.6503 - val_accuracy: 0.6579\n",
      "Epoch 10/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6450 - val_loss: 0.6518 - val_accuracy: 0.6541\n",
      "Epoch 11/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6413 - val_loss: 0.6485 - val_accuracy: 0.6598\n",
      "Epoch 12/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6432 - val_loss: 0.6519 - val_accuracy: 0.6541\n",
      "Epoch 13/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6432 - val_loss: 0.6441 - val_accuracy: 0.6579\n",
      "Epoch 14/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6450 - val_loss: 0.6444 - val_accuracy: 0.6560\n",
      "Epoch 15/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6450 - val_loss: 0.6444 - val_accuracy: 0.6560\n",
      "Epoch 16/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6469 - val_loss: 0.6434 - val_accuracy: 0.6598\n",
      "Epoch 17/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6487 - val_loss: 0.6435 - val_accuracy: 0.6579\n",
      "Epoch 18/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6460 - val_loss: 0.6476 - val_accuracy: 0.6598\n",
      "Epoch 19/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6441 - val_loss: 0.6413 - val_accuracy: 0.6579\n",
      "Epoch 20/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6460 - val_loss: 0.6393 - val_accuracy: 0.6579\n",
      "Epoch 21/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6497 - val_loss: 0.6406 - val_accuracy: 0.6541\n",
      "Epoch 22/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6469 - val_loss: 0.6384 - val_accuracy: 0.6617\n",
      "Epoch 23/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6469 - val_loss: 0.6376 - val_accuracy: 0.6523\n",
      "Epoch 24/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6460 - val_loss: 0.6364 - val_accuracy: 0.6541\n",
      "Epoch 25/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6450 - val_loss: 0.6430 - val_accuracy: 0.6579\n",
      "Epoch 26/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6413 - val_loss: 0.6320 - val_accuracy: 0.6617\n",
      "Epoch 27/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6478 - val_loss: 0.6453 - val_accuracy: 0.6579\n",
      "Epoch 28/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6270 - accuracy: 0.6478 - val_loss: 0.6311 - val_accuracy: 0.6579\n",
      "Epoch 29/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6469 - val_loss: 0.6285 - val_accuracy: 0.6598\n",
      "Epoch 30/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6525 - val_loss: 0.6219 - val_accuracy: 0.6617\n",
      "Epoch 31/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.6515 - val_loss: 0.6184 - val_accuracy: 0.6579\n",
      "Epoch 32/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6571 - val_loss: 0.6038 - val_accuracy: 0.6635\n",
      "Epoch 33/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.6840 - val_loss: 0.6036 - val_accuracy: 0.6917\n",
      "Epoch 34/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6969 - val_loss: 0.6312 - val_accuracy: 0.6692\n",
      "Epoch 35/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7044 - val_loss: 0.5831 - val_accuracy: 0.7162\n",
      "Epoch 36/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6979 - val_loss: 0.5757 - val_accuracy: 0.7049\n",
      "Epoch 37/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7340 - val_loss: 0.6011 - val_accuracy: 0.6673\n",
      "Epoch 38/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7368 - val_loss: 0.5722 - val_accuracy: 0.7350\n",
      "Epoch 39/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7386 - val_loss: 0.5803 - val_accuracy: 0.7011\n",
      "Epoch 40/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7590 - val_loss: 0.6195 - val_accuracy: 0.7086\n",
      "Epoch 41/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7572 - val_loss: 0.5479 - val_accuracy: 0.7124\n",
      "Epoch 42/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5265 - val_accuracy: 0.7462\n",
      "Epoch 43/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7757 - val_loss: 0.5264 - val_accuracy: 0.7632\n",
      "Epoch 44/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7924 - val_loss: 0.5359 - val_accuracy: 0.7331\n",
      "Epoch 45/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7878 - val_loss: 0.5003 - val_accuracy: 0.7744\n",
      "Epoch 46/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7794 - val_loss: 0.5005 - val_accuracy: 0.7763\n",
      "Epoch 47/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7785 - val_loss: 0.5181 - val_accuracy: 0.7368\n",
      "Epoch 48/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7952 - val_loss: 0.4999 - val_accuracy: 0.7782\n",
      "Epoch 49/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7998 - val_loss: 0.4913 - val_accuracy: 0.7782\n",
      "Epoch 50/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7887 - val_loss: 0.4868 - val_accuracy: 0.7707\n",
      "Epoch 51/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.8082 - val_loss: 0.5375 - val_accuracy: 0.7632\n",
      "Epoch 52/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8137 - val_loss: 0.5432 - val_accuracy: 0.7632\n",
      "Epoch 53/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7943 - val_loss: 0.5474 - val_accuracy: 0.7350\n",
      "Epoch 54/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8165 - val_loss: 0.6266 - val_accuracy: 0.7293\n",
      "Epoch 55/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8165 - val_loss: 0.5088 - val_accuracy: 0.7857\n",
      "Epoch 56/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8026 - val_loss: 0.4819 - val_accuracy: 0.7782\n",
      "Epoch 57/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8156 - val_loss: 0.4898 - val_accuracy: 0.7820\n",
      "Epoch 58/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8146 - val_loss: 0.4935 - val_accuracy: 0.7895\n",
      "Epoch 59/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8156 - val_loss: 0.4842 - val_accuracy: 0.7838\n",
      "Epoch 60/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8082 - val_loss: 0.4869 - val_accuracy: 0.7857\n",
      "Epoch 61/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7961 - val_loss: 0.4791 - val_accuracy: 0.7895\n",
      "Epoch 62/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8193 - val_loss: 0.4783 - val_accuracy: 0.7895\n",
      "Epoch 63/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8276 - val_loss: 0.5019 - val_accuracy: 0.7838\n",
      "Epoch 64/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8082 - val_loss: 0.4904 - val_accuracy: 0.7556\n",
      "Epoch 65/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8174 - val_loss: 0.4695 - val_accuracy: 0.7932\n",
      "Epoch 66/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8100 - val_loss: 0.4656 - val_accuracy: 0.7932\n",
      "Epoch 67/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8239 - val_loss: 0.4917 - val_accuracy: 0.7876\n",
      "Epoch 68/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8044 - val_loss: 0.4777 - val_accuracy: 0.7801\n",
      "Epoch 69/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7952 - val_loss: 0.4670 - val_accuracy: 0.7970\n",
      "Epoch 70/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8267 - val_loss: 0.4645 - val_accuracy: 0.7895\n",
      "Epoch 71/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8137 - val_loss: 0.4821 - val_accuracy: 0.7895\n",
      "Epoch 72/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8165 - val_loss: 0.4734 - val_accuracy: 0.7782\n",
      "Epoch 73/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8276 - val_loss: 0.4706 - val_accuracy: 0.7857\n",
      "Epoch 74/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8184 - val_loss: 0.4691 - val_accuracy: 0.7838\n",
      "Epoch 75/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8221 - val_loss: 0.4767 - val_accuracy: 0.7744\n",
      "Epoch 76/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8221 - val_loss: 0.4564 - val_accuracy: 0.7914\n",
      "Epoch 77/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8230 - val_loss: 0.4605 - val_accuracy: 0.8008\n",
      "Epoch 78/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8341 - val_loss: 0.4712 - val_accuracy: 0.7895\n",
      "Epoch 79/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8211 - val_loss: 0.4746 - val_accuracy: 0.7914\n",
      "Epoch 80/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8350 - val_loss: 0.5090 - val_accuracy: 0.7857\n",
      "Epoch 81/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8313 - val_loss: 0.4668 - val_accuracy: 0.7876\n",
      "Epoch 82/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8313 - val_loss: 0.4913 - val_accuracy: 0.7876\n",
      "Epoch 83/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8323 - val_loss: 0.4575 - val_accuracy: 0.7932\n",
      "Epoch 84/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8323 - val_loss: 0.4823 - val_accuracy: 0.7876\n",
      "Epoch 85/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8248 - val_loss: 0.4609 - val_accuracy: 0.7895\n",
      "Epoch 86/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8387 - val_loss: 0.4920 - val_accuracy: 0.7744\n",
      "Epoch 87/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8230 - val_loss: 0.4882 - val_accuracy: 0.7932\n",
      "Epoch 88/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8285 - val_loss: 0.4564 - val_accuracy: 0.8045\n",
      "Epoch 89/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8221 - val_loss: 0.4802 - val_accuracy: 0.8026\n",
      "Epoch 90/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8526 - val_loss: 0.4710 - val_accuracy: 0.7932\n",
      "Epoch 91/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8304 - val_loss: 0.4516 - val_accuracy: 0.8064\n",
      "Epoch 92/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8350 - val_loss: 0.4496 - val_accuracy: 0.8008\n",
      "Epoch 93/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8424 - val_loss: 0.4524 - val_accuracy: 0.8158\n",
      "Epoch 94/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8332 - val_loss: 0.4517 - val_accuracy: 0.8045\n",
      "Epoch 95/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8397 - val_loss: 0.4520 - val_accuracy: 0.8120\n",
      "Epoch 96/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8323 - val_loss: 0.4886 - val_accuracy: 0.7951\n",
      "Epoch 97/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8517 - val_loss: 0.4492 - val_accuracy: 0.8026\n",
      "Epoch 98/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8443 - val_loss: 0.4647 - val_accuracy: 0.8026\n",
      "Epoch 99/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8323 - val_loss: 0.4714 - val_accuracy: 0.8064\n",
      "Epoch 100/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8397 - val_loss: 0.4603 - val_accuracy: 0.8102\n",
      "Epoch 101/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8489 - val_loss: 0.4613 - val_accuracy: 0.7970\n",
      "Epoch 102/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8424 - val_loss: 0.4948 - val_accuracy: 0.7801\n",
      "Epoch 103/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8406 - val_loss: 0.4617 - val_accuracy: 0.8045\n",
      "Epoch 104/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8471 - val_loss: 0.4539 - val_accuracy: 0.8158\n",
      "Epoch 105/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8489 - val_loss: 0.5482 - val_accuracy: 0.7688\n",
      "Epoch 106/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8443 - val_loss: 0.4497 - val_accuracy: 0.8045\n",
      "Epoch 107/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8424 - val_loss: 0.4801 - val_accuracy: 0.7876\n",
      "Epoch 108/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8193 - val_loss: 0.5157 - val_accuracy: 0.7632\n",
      "Epoch 109/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8323 - val_loss: 0.5334 - val_accuracy: 0.7575\n",
      "Epoch 110/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8267 - val_loss: 0.4636 - val_accuracy: 0.8083\n",
      "Epoch 111/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8508 - val_loss: 0.4573 - val_accuracy: 0.8102\n",
      "Epoch 112/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8406 - val_loss: 0.4449 - val_accuracy: 0.8102\n",
      "Epoch 113/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8434 - val_loss: 0.4408 - val_accuracy: 0.8158\n",
      "Epoch 114/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8471 - val_loss: 0.5514 - val_accuracy: 0.7481\n",
      "Epoch 115/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8406 - val_loss: 0.4552 - val_accuracy: 0.8102\n",
      "Epoch 116/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8378 - val_loss: 0.4476 - val_accuracy: 0.8214\n",
      "Epoch 117/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8424 - val_loss: 0.4654 - val_accuracy: 0.8064\n",
      "Epoch 118/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8508 - val_loss: 0.4468 - val_accuracy: 0.8195\n",
      "Epoch 119/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8424 - val_loss: 0.4359 - val_accuracy: 0.8195\n",
      "Epoch 120/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8313 - val_loss: 0.4461 - val_accuracy: 0.8120\n",
      "Epoch 121/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8554 - val_loss: 0.4602 - val_accuracy: 0.8064\n",
      "Epoch 122/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8443 - val_loss: 0.4846 - val_accuracy: 0.7951\n",
      "Epoch 123/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8508 - val_loss: 0.4553 - val_accuracy: 0.8252\n",
      "Epoch 124/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8489 - val_loss: 0.4346 - val_accuracy: 0.8252\n",
      "Epoch 125/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8489 - val_loss: 0.4664 - val_accuracy: 0.8120\n",
      "Epoch 126/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8452 - val_loss: 0.4501 - val_accuracy: 0.8102\n",
      "Epoch 127/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8267 - val_loss: 0.4776 - val_accuracy: 0.7970\n",
      "Epoch 128/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8554 - val_loss: 0.4565 - val_accuracy: 0.8120\n",
      "Epoch 129/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8397 - val_loss: 0.4542 - val_accuracy: 0.8139\n",
      "Epoch 130/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8360 - val_loss: 0.4443 - val_accuracy: 0.8158\n",
      "Epoch 131/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8591 - val_loss: 0.4408 - val_accuracy: 0.8139\n",
      "Epoch 132/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8563 - val_loss: 0.4391 - val_accuracy: 0.8177\n",
      "Epoch 133/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8480 - val_loss: 0.4573 - val_accuracy: 0.8214\n",
      "Epoch 134/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8471 - val_loss: 0.4382 - val_accuracy: 0.8177\n",
      "Epoch 135/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8452 - val_loss: 0.4394 - val_accuracy: 0.8252\n",
      "Epoch 136/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8443 - val_loss: 0.4610 - val_accuracy: 0.8102\n",
      "Epoch 137/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8499 - val_loss: 0.4456 - val_accuracy: 0.8102\n",
      "Epoch 138/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8489 - val_loss: 0.4810 - val_accuracy: 0.7970\n",
      "Epoch 139/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8526 - val_loss: 0.4382 - val_accuracy: 0.8158\n",
      "Epoch 140/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8406 - val_loss: 0.4466 - val_accuracy: 0.8233\n",
      "Epoch 141/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8582 - val_loss: 0.4670 - val_accuracy: 0.8064\n",
      "Epoch 142/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8397 - val_loss: 0.5201 - val_accuracy: 0.7688\n",
      "Epoch 143/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8369 - val_loss: 0.4318 - val_accuracy: 0.8214\n",
      "Epoch 144/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8462 - val_loss: 0.4367 - val_accuracy: 0.8233\n",
      "Epoch 145/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8517 - val_loss: 0.4503 - val_accuracy: 0.8139\n",
      "Epoch 146/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8536 - val_loss: 0.4458 - val_accuracy: 0.8195\n",
      "Epoch 147/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8508 - val_loss: 0.4628 - val_accuracy: 0.8083\n",
      "Epoch 148/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8545 - val_loss: 0.4317 - val_accuracy: 0.8271\n",
      "Epoch 149/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8582 - val_loss: 0.4427 - val_accuracy: 0.8195\n",
      "Epoch 150/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8536 - val_loss: 0.4922 - val_accuracy: 0.7895\n",
      "Epoch 151/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8406 - val_loss: 0.4551 - val_accuracy: 0.8158\n",
      "Epoch 152/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8610 - val_loss: 0.4576 - val_accuracy: 0.8102\n",
      "Epoch 153/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8526 - val_loss: 0.4514 - val_accuracy: 0.8195\n",
      "Epoch 154/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8545 - val_loss: 0.4986 - val_accuracy: 0.7744\n",
      "Epoch 155/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8508 - val_loss: 0.4374 - val_accuracy: 0.8214\n",
      "Epoch 156/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8489 - val_loss: 0.4465 - val_accuracy: 0.8214\n",
      "Epoch 157/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8462 - val_loss: 0.4443 - val_accuracy: 0.8233\n",
      "Epoch 158/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8536 - val_loss: 0.4606 - val_accuracy: 0.8045\n",
      "Epoch 159/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8350 - val_loss: 0.4518 - val_accuracy: 0.8233\n",
      "Epoch 160/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8471 - val_loss: 0.4690 - val_accuracy: 0.7989\n",
      "Epoch 161/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8480 - val_loss: 0.4472 - val_accuracy: 0.8214\n",
      "Epoch 162/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8554 - val_loss: 0.4492 - val_accuracy: 0.8083\n",
      "Epoch 163/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8471 - val_loss: 0.4659 - val_accuracy: 0.8008\n",
      "Epoch 164/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8675 - val_loss: 0.4658 - val_accuracy: 0.8177\n",
      "Epoch 165/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8452 - val_loss: 0.4444 - val_accuracy: 0.8139\n",
      "Epoch 166/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8563 - val_loss: 0.4319 - val_accuracy: 0.8327\n",
      "Epoch 167/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8499 - val_loss: 0.4773 - val_accuracy: 0.7970\n",
      "Epoch 168/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8471 - val_loss: 0.4384 - val_accuracy: 0.8139\n",
      "Epoch 169/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8471 - val_loss: 0.4641 - val_accuracy: 0.8008\n",
      "Epoch 170/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8480 - val_loss: 0.4426 - val_accuracy: 0.8233\n",
      "Epoch 171/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8647 - val_loss: 0.4586 - val_accuracy: 0.8289\n",
      "Epoch 172/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8526 - val_loss: 0.4494 - val_accuracy: 0.8252\n",
      "Epoch 173/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8508 - val_loss: 0.4763 - val_accuracy: 0.8158\n",
      "Epoch 174/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8656 - val_loss: 0.4391 - val_accuracy: 0.8271\n",
      "Epoch 175/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8545 - val_loss: 0.4383 - val_accuracy: 0.8233\n",
      "Epoch 176/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8573 - val_loss: 0.4427 - val_accuracy: 0.8271\n",
      "Epoch 177/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8508 - val_loss: 0.4427 - val_accuracy: 0.8233\n",
      "Epoch 178/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8517 - val_loss: 0.4775 - val_accuracy: 0.8008\n",
      "Epoch 179/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8480 - val_loss: 0.4943 - val_accuracy: 0.7895\n",
      "Epoch 180/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8619 - val_loss: 0.4491 - val_accuracy: 0.8177\n",
      "Epoch 181/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8452 - val_loss: 0.4398 - val_accuracy: 0.8214\n",
      "Epoch 182/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8563 - val_loss: 0.5141 - val_accuracy: 0.7801\n",
      "Epoch 183/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8554 - val_loss: 0.4572 - val_accuracy: 0.8233\n",
      "Epoch 184/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8526 - val_loss: 0.4870 - val_accuracy: 0.7895\n",
      "Epoch 185/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8443 - val_loss: 0.4356 - val_accuracy: 0.8252\n",
      "Epoch 186/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8397 - val_loss: 0.4688 - val_accuracy: 0.8064\n",
      "Epoch 187/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8591 - val_loss: 0.4515 - val_accuracy: 0.8252\n",
      "Epoch 188/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8601 - val_loss: 0.4645 - val_accuracy: 0.7989\n",
      "Epoch 189/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8332 - val_loss: 0.4265 - val_accuracy: 0.8365\n",
      "Epoch 190/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8563 - val_loss: 0.4644 - val_accuracy: 0.8120\n",
      "Epoch 191/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8452 - val_loss: 0.4269 - val_accuracy: 0.8233\n",
      "Epoch 192/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8517 - val_loss: 0.4584 - val_accuracy: 0.8139\n",
      "Epoch 193/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8610 - val_loss: 0.4529 - val_accuracy: 0.8120\n",
      "Epoch 194/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8480 - val_loss: 0.4417 - val_accuracy: 0.8233\n",
      "Epoch 195/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8638 - val_loss: 0.4614 - val_accuracy: 0.8271\n",
      "Epoch 196/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8517 - val_loss: 0.5040 - val_accuracy: 0.7914\n",
      "Epoch 197/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8508 - val_loss: 0.4495 - val_accuracy: 0.8214\n",
      "Epoch 198/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8582 - val_loss: 0.4603 - val_accuracy: 0.8120\n",
      "Epoch 199/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8573 - val_loss: 0.4347 - val_accuracy: 0.8195\n",
      "Epoch 200/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8573 - val_loss: 0.5012 - val_accuracy: 0.7970\n",
      "Epoch 201/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8517 - val_loss: 0.4396 - val_accuracy: 0.8252\n",
      "Epoch 202/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8536 - val_loss: 0.4479 - val_accuracy: 0.8120\n",
      "Epoch 203/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8443 - val_loss: 0.4389 - val_accuracy: 0.8289\n",
      "Epoch 204/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8619 - val_loss: 0.4753 - val_accuracy: 0.8008\n",
      "Epoch 205/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8591 - val_loss: 0.4976 - val_accuracy: 0.7932\n",
      "Epoch 206/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8610 - val_loss: 0.4306 - val_accuracy: 0.8289\n",
      "Epoch 207/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8545 - val_loss: 0.4409 - val_accuracy: 0.8233\n",
      "Epoch 208/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8462 - val_loss: 0.4727 - val_accuracy: 0.8214\n",
      "Epoch 209/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8665 - val_loss: 0.5675 - val_accuracy: 0.7632\n",
      "Epoch 210/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8341 - val_loss: 0.4294 - val_accuracy: 0.8252\n",
      "Epoch 211/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8582 - val_loss: 0.4377 - val_accuracy: 0.8271\n",
      "Epoch 212/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8573 - val_loss: 0.4505 - val_accuracy: 0.8252\n",
      "Epoch 213/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8526 - val_loss: 0.4282 - val_accuracy: 0.8308\n",
      "Epoch 214/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8415 - val_loss: 0.4405 - val_accuracy: 0.8214\n",
      "Epoch 215/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8638 - val_loss: 0.4718 - val_accuracy: 0.7932\n",
      "Epoch 216/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8526 - val_loss: 0.4731 - val_accuracy: 0.8139\n",
      "Epoch 217/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8489 - val_loss: 0.4350 - val_accuracy: 0.8252\n",
      "Epoch 218/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8582 - val_loss: 0.4545 - val_accuracy: 0.8252\n",
      "Epoch 219/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8610 - val_loss: 0.4276 - val_accuracy: 0.8271\n",
      "Epoch 220/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8638 - val_loss: 0.4462 - val_accuracy: 0.8158\n",
      "Epoch 221/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8573 - val_loss: 0.4418 - val_accuracy: 0.8233\n",
      "Epoch 222/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8619 - val_loss: 0.4436 - val_accuracy: 0.8233\n",
      "Epoch 223/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8508 - val_loss: 0.4393 - val_accuracy: 0.8252\n",
      "Epoch 224/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8489 - val_loss: 0.4566 - val_accuracy: 0.8139\n",
      "Epoch 225/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8619 - val_loss: 0.4425 - val_accuracy: 0.8327\n",
      "Epoch 226/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8628 - val_loss: 0.5086 - val_accuracy: 0.7688\n",
      "Epoch 227/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8545 - val_loss: 0.4422 - val_accuracy: 0.8233\n",
      "Epoch 228/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8610 - val_loss: 0.4558 - val_accuracy: 0.8214\n",
      "Epoch 229/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8424 - val_loss: 0.4449 - val_accuracy: 0.8252\n",
      "Epoch 230/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8665 - val_loss: 0.4551 - val_accuracy: 0.8139\n",
      "Epoch 231/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8563 - val_loss: 0.4398 - val_accuracy: 0.8177\n",
      "Epoch 232/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8499 - val_loss: 0.4467 - val_accuracy: 0.8102\n",
      "Epoch 233/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8499 - val_loss: 0.4466 - val_accuracy: 0.8252\n",
      "Epoch 234/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8656 - val_loss: 0.4859 - val_accuracy: 0.7989\n",
      "Epoch 235/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8536 - val_loss: 0.4598 - val_accuracy: 0.8177\n",
      "Epoch 236/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8628 - val_loss: 0.4518 - val_accuracy: 0.8177\n",
      "Epoch 237/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8591 - val_loss: 0.5218 - val_accuracy: 0.7801\n",
      "Epoch 238/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8573 - val_loss: 0.4295 - val_accuracy: 0.8308\n",
      "Epoch 239/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8665 - val_loss: 0.4394 - val_accuracy: 0.8214\n",
      "Epoch 240/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8573 - val_loss: 0.4433 - val_accuracy: 0.8271\n",
      "Epoch 241/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8601 - val_loss: 0.4484 - val_accuracy: 0.8214\n",
      "Epoch 242/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8684 - val_loss: 0.4488 - val_accuracy: 0.8139\n",
      "Epoch 243/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8638 - val_loss: 0.4905 - val_accuracy: 0.7970\n",
      "Epoch 244/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8693 - val_loss: 0.4426 - val_accuracy: 0.8233\n",
      "Epoch 245/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8378 - val_loss: 0.5120 - val_accuracy: 0.7876\n",
      "Epoch 246/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8638 - val_loss: 0.4706 - val_accuracy: 0.8139\n",
      "Epoch 247/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8740 - val_loss: 0.4853 - val_accuracy: 0.8139\n",
      "Epoch 248/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8563 - val_loss: 0.4489 - val_accuracy: 0.8289\n",
      "Epoch 249/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8675 - val_loss: 0.4529 - val_accuracy: 0.8214\n",
      "Epoch 250/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8619 - val_loss: 0.4956 - val_accuracy: 0.7951\n",
      "Epoch 251/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8582 - val_loss: 0.4524 - val_accuracy: 0.8177\n",
      "Epoch 252/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8526 - val_loss: 0.4826 - val_accuracy: 0.8083\n",
      "Epoch 253/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8591 - val_loss: 0.4468 - val_accuracy: 0.8252\n",
      "Epoch 254/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8665 - val_loss: 0.4566 - val_accuracy: 0.8214\n",
      "Epoch 255/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8573 - val_loss: 0.4799 - val_accuracy: 0.8064\n",
      "Epoch 256/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8647 - val_loss: 0.4576 - val_accuracy: 0.8102\n",
      "Epoch 257/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8730 - val_loss: 0.4453 - val_accuracy: 0.8102\n",
      "Epoch 258/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8601 - val_loss: 0.4748 - val_accuracy: 0.7989\n",
      "Epoch 259/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8610 - val_loss: 0.4359 - val_accuracy: 0.8139\n",
      "Epoch 260/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8638 - val_loss: 0.5005 - val_accuracy: 0.8026\n",
      "Epoch 261/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8517 - val_loss: 0.5169 - val_accuracy: 0.7876\n",
      "Epoch 262/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8434 - val_loss: 0.7495 - val_accuracy: 0.7180\n",
      "Epoch 263/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8545 - val_loss: 0.4382 - val_accuracy: 0.8233\n",
      "Epoch 264/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8601 - val_loss: 0.4546 - val_accuracy: 0.8252\n",
      "Epoch 265/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8628 - val_loss: 0.4783 - val_accuracy: 0.8158\n",
      "Epoch 266/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8656 - val_loss: 0.4928 - val_accuracy: 0.7876\n",
      "Epoch 267/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8675 - val_loss: 0.4344 - val_accuracy: 0.8233\n",
      "Epoch 268/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8740 - val_loss: 0.4931 - val_accuracy: 0.8102\n",
      "Epoch 269/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8721 - val_loss: 0.4716 - val_accuracy: 0.8083\n",
      "Epoch 270/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8591 - val_loss: 0.4487 - val_accuracy: 0.8214\n",
      "Epoch 271/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8656 - val_loss: 0.4437 - val_accuracy: 0.8177\n",
      "Epoch 272/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8591 - val_loss: 0.4666 - val_accuracy: 0.8102\n",
      "Epoch 273/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8628 - val_loss: 0.4655 - val_accuracy: 0.8102\n",
      "Epoch 274/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8628 - val_loss: 0.4630 - val_accuracy: 0.8195\n",
      "Epoch 275/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8647 - val_loss: 0.4637 - val_accuracy: 0.8289\n",
      "Epoch 276/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8517 - val_loss: 0.4413 - val_accuracy: 0.8271\n",
      "Epoch 277/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8601 - val_loss: 0.4546 - val_accuracy: 0.8233\n",
      "Epoch 278/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8610 - val_loss: 0.4779 - val_accuracy: 0.8026\n",
      "Epoch 279/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8647 - val_loss: 0.4801 - val_accuracy: 0.8139\n",
      "Epoch 280/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8582 - val_loss: 0.4559 - val_accuracy: 0.8214\n",
      "Epoch 281/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8665 - val_loss: 0.5388 - val_accuracy: 0.7782\n",
      "Epoch 282/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8601 - val_loss: 0.4579 - val_accuracy: 0.8195\n",
      "Epoch 283/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8684 - val_loss: 0.4499 - val_accuracy: 0.8252\n",
      "Epoch 284/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8693 - val_loss: 0.4905 - val_accuracy: 0.8102\n",
      "Epoch 285/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8638 - val_loss: 0.5017 - val_accuracy: 0.7932\n",
      "Epoch 286/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8610 - val_loss: 0.4920 - val_accuracy: 0.8083\n",
      "Epoch 287/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8591 - val_loss: 0.4504 - val_accuracy: 0.8214\n",
      "Epoch 288/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8638 - val_loss: 0.5344 - val_accuracy: 0.7970\n",
      "Epoch 289/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8462 - val_loss: 0.4549 - val_accuracy: 0.8158\n",
      "Epoch 290/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8545 - val_loss: 0.4622 - val_accuracy: 0.8195\n",
      "Epoch 291/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8628 - val_loss: 0.4761 - val_accuracy: 0.8102\n",
      "Epoch 292/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8656 - val_loss: 0.4822 - val_accuracy: 0.8083\n",
      "Epoch 293/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8628 - val_loss: 0.5258 - val_accuracy: 0.7801\n",
      "Epoch 294/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8591 - val_loss: 0.4419 - val_accuracy: 0.8233\n",
      "Epoch 295/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8582 - val_loss: 0.4878 - val_accuracy: 0.8045\n",
      "Epoch 296/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8665 - val_loss: 0.4721 - val_accuracy: 0.8139\n",
      "Epoch 297/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8573 - val_loss: 0.4573 - val_accuracy: 0.8214\n",
      "Epoch 298/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8730 - val_loss: 0.4670 - val_accuracy: 0.8195\n",
      "Epoch 299/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8591 - val_loss: 0.4711 - val_accuracy: 0.8139\n",
      "Epoch 300/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8601 - val_loss: 0.4514 - val_accuracy: 0.8214\n",
      "Epoch 301/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8582 - val_loss: 0.4566 - val_accuracy: 0.8102\n",
      "Epoch 302/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8656 - val_loss: 0.4711 - val_accuracy: 0.8214\n",
      "Epoch 303/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8647 - val_loss: 0.4790 - val_accuracy: 0.8008\n",
      "Epoch 304/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8647 - val_loss: 0.4937 - val_accuracy: 0.8102\n",
      "Epoch 305/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8601 - val_loss: 0.4717 - val_accuracy: 0.8177\n",
      "Epoch 306/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8656 - val_loss: 0.4781 - val_accuracy: 0.8158\n",
      "Epoch 307/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8665 - val_loss: 0.5548 - val_accuracy: 0.7707\n",
      "Epoch 308/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8610 - val_loss: 0.4666 - val_accuracy: 0.8214\n",
      "Epoch 309/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8693 - val_loss: 0.4870 - val_accuracy: 0.8102\n",
      "Epoch 310/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8554 - val_loss: 0.4585 - val_accuracy: 0.8139\n",
      "Epoch 311/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8628 - val_loss: 0.4646 - val_accuracy: 0.8195\n",
      "Epoch 312/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8628 - val_loss: 0.4564 - val_accuracy: 0.8195\n",
      "Epoch 313/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8647 - val_loss: 0.4611 - val_accuracy: 0.8158\n",
      "Epoch 314/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8656 - val_loss: 0.4684 - val_accuracy: 0.8195\n",
      "Epoch 315/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8693 - val_loss: 0.4549 - val_accuracy: 0.8271\n",
      "Epoch 316/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8619 - val_loss: 0.5196 - val_accuracy: 0.7932\n",
      "Epoch 317/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8554 - val_loss: 0.4539 - val_accuracy: 0.8214\n",
      "Epoch 318/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8610 - val_loss: 0.4475 - val_accuracy: 0.8214\n",
      "Epoch 319/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8665 - val_loss: 0.4902 - val_accuracy: 0.8158\n",
      "Epoch 320/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8601 - val_loss: 0.4539 - val_accuracy: 0.8139\n",
      "Epoch 321/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8703 - val_loss: 0.4495 - val_accuracy: 0.8233\n",
      "Epoch 322/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8675 - val_loss: 0.4436 - val_accuracy: 0.8271\n",
      "Epoch 323/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8684 - val_loss: 0.4588 - val_accuracy: 0.8195\n",
      "Epoch 324/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8712 - val_loss: 0.4544 - val_accuracy: 0.8177\n",
      "Epoch 325/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8582 - val_loss: 0.4939 - val_accuracy: 0.8139\n",
      "Epoch 326/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8545 - val_loss: 0.4614 - val_accuracy: 0.8177\n",
      "Epoch 327/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8480 - val_loss: 0.4392 - val_accuracy: 0.8252\n",
      "Epoch 328/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8647 - val_loss: 0.4595 - val_accuracy: 0.8177\n",
      "Epoch 329/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8675 - val_loss: 0.4576 - val_accuracy: 0.8177\n",
      "Epoch 330/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8712 - val_loss: 0.4874 - val_accuracy: 0.8102\n",
      "Epoch 331/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8563 - val_loss: 0.4838 - val_accuracy: 0.8064\n",
      "Epoch 332/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8703 - val_loss: 0.5094 - val_accuracy: 0.8026\n",
      "Epoch 333/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8703 - val_loss: 0.4632 - val_accuracy: 0.8214\n",
      "Epoch 334/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8610 - val_loss: 0.4842 - val_accuracy: 0.8064\n",
      "Epoch 335/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8489 - val_loss: 0.4419 - val_accuracy: 0.8195\n",
      "Epoch 336/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.8730 - val_loss: 0.4767 - val_accuracy: 0.8158\n",
      "Epoch 337/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8554 - val_loss: 0.4615 - val_accuracy: 0.8177\n",
      "Epoch 338/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8619 - val_loss: 0.4568 - val_accuracy: 0.8177\n",
      "Epoch 339/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8675 - val_loss: 0.4689 - val_accuracy: 0.8158\n",
      "Epoch 340/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8591 - val_loss: 0.5256 - val_accuracy: 0.7726\n",
      "Epoch 341/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8675 - val_loss: 0.4560 - val_accuracy: 0.8195\n",
      "Epoch 342/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8573 - val_loss: 0.5090 - val_accuracy: 0.8045\n",
      "Epoch 343/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8703 - val_loss: 0.5005 - val_accuracy: 0.8008\n",
      "Epoch 344/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8665 - val_loss: 0.4748 - val_accuracy: 0.8158\n",
      "Epoch 345/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8638 - val_loss: 0.4819 - val_accuracy: 0.8120\n",
      "Epoch 346/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8693 - val_loss: 0.4680 - val_accuracy: 0.8233\n",
      "Epoch 347/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8758 - val_loss: 0.4765 - val_accuracy: 0.8158\n",
      "Epoch 348/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8758 - val_loss: 0.4772 - val_accuracy: 0.8158\n",
      "Epoch 349/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8693 - val_loss: 0.4737 - val_accuracy: 0.8233\n",
      "Epoch 350/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3195 - accuracy: 0.8675 - val_loss: 0.4839 - val_accuracy: 0.8139\n",
      "Epoch 351/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8684 - val_loss: 0.4700 - val_accuracy: 0.8195\n",
      "Epoch 352/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8703 - val_loss: 0.4759 - val_accuracy: 0.8102\n",
      "Epoch 353/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8721 - val_loss: 0.5201 - val_accuracy: 0.7989\n",
      "Epoch 354/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8712 - val_loss: 0.4733 - val_accuracy: 0.8252\n",
      "Epoch 355/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8684 - val_loss: 0.4928 - val_accuracy: 0.8102\n",
      "Epoch 356/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8591 - val_loss: 0.4578 - val_accuracy: 0.8158\n",
      "Epoch 357/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8684 - val_loss: 0.4722 - val_accuracy: 0.8252\n",
      "Epoch 358/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8619 - val_loss: 0.4576 - val_accuracy: 0.8102\n",
      "Epoch 359/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8730 - val_loss: 0.4453 - val_accuracy: 0.8120\n",
      "Epoch 360/360\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8758 - val_loss: 0.4654 - val_accuracy: 0.8102\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(xtrain,ytrain,validation_split=0.33,batch_size=10,epochs=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 720us/step\n",
      "Accuracy: 0.8197026022304833\n"
     ]
    }
   ],
   "source": [
    "predicted3=classifier.predict(xtest)\n",
    "predicted_classes = (predicted3 > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(ytest, predicted_classes)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2149 entries, 0 to 2148\n",
      "Data columns (total 33 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Age                        2149 non-null   int64  \n",
      " 1   Gender                     2149 non-null   int64  \n",
      " 2   Ethnicity                  2149 non-null   int64  \n",
      " 3   EducationLevel             2149 non-null   int64  \n",
      " 4   BMI                        2149 non-null   float64\n",
      " 5   Smoking                    2149 non-null   int64  \n",
      " 6   AlcoholConsumption         2149 non-null   float64\n",
      " 7   PhysicalActivity           2149 non-null   float64\n",
      " 8   DietQuality                2149 non-null   float64\n",
      " 9   SleepQuality               2149 non-null   float64\n",
      " 10  FamilyHistoryAlzheimers    2149 non-null   int64  \n",
      " 11  CardiovascularDisease      2149 non-null   int64  \n",
      " 12  Diabetes                   2149 non-null   int64  \n",
      " 13  Depression                 2149 non-null   int64  \n",
      " 14  HeadInjury                 2149 non-null   int64  \n",
      " 15  Hypertension               2149 non-null   int64  \n",
      " 16  SystolicBP                 2149 non-null   int64  \n",
      " 17  DiastolicBP                2149 non-null   int64  \n",
      " 18  CholesterolTotal           2149 non-null   float64\n",
      " 19  CholesterolLDL             2149 non-null   float64\n",
      " 20  CholesterolHDL             2149 non-null   float64\n",
      " 21  CholesterolTriglycerides   2149 non-null   float64\n",
      " 22  MMSE                       2149 non-null   float64\n",
      " 23  FunctionalAssessment       2149 non-null   float64\n",
      " 24  MemoryComplaints           2149 non-null   int64  \n",
      " 25  BehavioralProblems         2149 non-null   int64  \n",
      " 26  ADL                        2149 non-null   float64\n",
      " 27  Confusion                  2149 non-null   int64  \n",
      " 28  Disorientation             2149 non-null   int64  \n",
      " 29  PersonalityChanges         2149 non-null   int64  \n",
      " 30  DifficultyCompletingTasks  2149 non-null   int64  \n",
      " 31  Forgetfulness              2149 non-null   int64  \n",
      " 32  Diagnosis                  2149 non-null   int64  \n",
      "dtypes: float64(12), int64(21)\n",
      "memory usage: 554.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2144    1\n",
       "2145    1\n",
       "2146    1\n",
       "2147    1\n",
       "2148    0\n",
       "Name: Diagnosis, Length: 2149, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
